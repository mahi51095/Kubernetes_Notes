# üìä Pod Scaling in Kubernetes (Simplified Notes)

## üé≠ Real-Time Metaphor

> Imagine running a **popular street food stall**.
>
> * In the **morning**, you need only **2 staff** (low demand).
> * In the **evening rush**, you need **10 staff** (high demand).
> * You want to **add or remove staff dynamically** based on the crowd.
>
> ‚úÖ **Pod scaling** is like adding/removing workers based on how many customers come in.

---

## ‚úÖ 5W1H: Pod Scaling

### 1Ô∏è‚É£ What is Pod Scaling?

The ability of Kubernetes to **increase or decrease the number of running Pods** for a workload based on demand.

Types:

* **Manual Scaling**: Human-controlled using `kubectl`
* **Auto Scaling**: Dynamic via HPA or external tools

### 2Ô∏è‚É£ Why is it Needed?

* To manage **varying traffic/load** efficiently
* To reduce **costs** by avoiding overprovisioning
* To maintain **availability** of services

### 3Ô∏è‚É£ When to Use?

* Peak load times (sales, events)
* Batch jobs or queue-based systems
* APIs that get traffic spikes

### 4Ô∏è‚É£ Where is it Applied?

* On **stateless applications**, **API services**, **workers**, etc.

### 5Ô∏è‚É£ Who Uses It?

* **DevOps Engineers**, **SREs**, **Platform teams**

### 6Ô∏è‚É£ How Does It Work?

* Manually via `kubectl scale`
* Automatically via HPA using CPU/memory metrics

---

## üõ†Ô∏è Detailed Setup Steps for HPA

### Step 1: ‚úÖ Apply Metrics Server (Required for HPA)

```bash
kubectl apply -f https://github.com/kubernetes-sigs/metrics-server/releases/latest/download/components.yaml
```

### Step 2: üîß Fix Metrics Server TLS Error (if needed)

If pod fails to come up due to certificate issue:

```bash
kubectl edit deploy metrics-server -n kube-system
```

‚û°Ô∏è Add this line in container args:

```yaml
- --kubelet-insecure-tls
```

Then save and exit. Wait for metrics server pod to become Ready.

### Step 3: üöÄ Create the Deployment, HPA, and Service

#### Deployment YAML

(see full example in "üì¶ Sample Deployment YAML" below)

#### HPA YAML (CPU + Memory)

(see "üìà HPA YAML" below)

#### Service YAML

(see "üåê Service YAML" below)

### Step 4: üîÑ Generate Load to Trigger Scaling

```bash
kubectl run -i --tty load-generator --rm --image=busybox /bin/sh
```

```bash
while true; do wget -q -O- http://hpaclusterservice; done
```

### Step 5: üëÄ Watch Auto Scaling in Action

```bash
watch kubectl get hpa
```

‚úÖ You‚Äôll observe replica count increase based on CPU/Memory usage.

---

## üñºÔ∏è Visual Representation

### Horizontal Pod Autoscaler Flow:

```
+--------------------------+
|  Metrics Server/Prometheus |
+-----------+--------------+
            |
            v
+--------------------------+
|  Horizontal Pod Autoscaler |
+-----------+--------------+
            |
            v
+--------------------------+
|   K8s Control Plane       |
+-----------+--------------+
            |
            v
+--------------------------+
|   Deployment/ReplicaSet   |
+-----------+--------------+
            |
            v
+--------------------------+
|       Pods (2‚Üí10)         |
+--------------------------+
```

### Pod Scaling Over Time:

```
Time ‚Üí
Load:     ‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë
Pods:     2     5       10     3
          |-----|-------|-----|
          |     |       |     |
        Morning Peak    Night
```

---

## üî∏ Manual Scaling

> Increasing/decreasing the number of Pods **manually** using `kubectl` or YAML.

```bash
kubectl scale deployment myapp --replicas=2  # or 3, 4, etc.
```

---

## üî∏ Types of Scaling in Kubernetes

### 1. üîº Horizontal Scaling

* Add more **Pods** to handle load
* Handled by **Horizontal Pod Autoscaler (HPA)**

### 2. üîΩ Vertical Scaling

* Increase **CPU/Memory** of the existing Pod
* Handled by **Vertical Pod Autoscaler (VPA)** (not covered here)

---

## üîÅ Kubernetes HPA vs AWS Auto Scaling

| Feature         | Kubernetes HPA                       | AWS Auto Scaling     |
| --------------- | ------------------------------------ | -------------------- |
| Object type     | HPA (Kubernetes object)              | Auto Scaling Group   |
| Unit of scaling | Pods                                 | EC2 instances        |
| Based on        | CPU/Memory/Custom Metrics            | CloudWatch Metrics   |
| Integrated with | K8s Metrics Server, Prometheus, etc. | EC2, ALB, CloudWatch |
| Platform scope  | Container Level (K8s)                | VM Level (AWS EC2)   |

---

## üì¶ Sample Deployment YAML

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: hpadeployment
  labels:
    name: hpadeployment
spec:
  replicas: 1
  selector:
    matchLabels:
      name: hpapod
  template:
    metadata:
      labels:
        name: hpapod
    spec:
      containers:
      - name: hpacontainer
        image: k8s.gcr.io/hpa-example
        ports:
        - name: http
          containerPort: 80
        resources:
          requests:
            cpu: "100m"
            memory: "64Mi"
          limits:
            cpu: "100m"
            memory: "128Mi"
```

---

## üìà HPA YAML (CPU + Memory)

```yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: hpadeploymentautoscaler
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: hpadeployment
  minReplicas: 2
  maxReplicas: 4
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 30
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

---

## üåê Service YAML

```yaml
apiVersion: v1
kind: Service
metadata:
  name: hpaclusterservice
  labels:
    name: hpaservice
spec:
  ports:
  - port: 80
    targetPort: 80
  selector:
    name: hpapod
  type: ClusterIP
```

---

‚úÖ Would you like to add Prometheus integration, vertical scaling, or interview questions?
